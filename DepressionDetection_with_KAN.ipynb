{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phN8lAeaFwF_"
      },
      "source": [
        "# Depression Detection using KANs\n",
        "To run the following code, ensure you have installed the packages mentioned in the README.MD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT66yuuQa1na",
        "outputId": "cb808350-b7fa-4640-c340-ee8bdeef895c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pykan\n",
            "  Downloading pykan-0.2.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.2/74.2 kB\u001b[0m \u001b[31m898.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pykan\n",
            "Successfully installed pykan-0.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install pykan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qae9oxq_Fy_B"
      },
      "source": [
        "Import all the python libraries required for the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XJL5ISybKAyS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from kan import KAN\n",
        "from kan import *\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqYfshkTyzhK"
      },
      "source": [
        "This Python script demonstrates how to use Kolmogorov-Arnold Networks (KANs) for binary classification task on a text dataset. It involves loading and preprocessing text data,  transforming it using TF-IDF, converting the training and testing sets into PyTorch tensors, training a KAN model, and evaluating its performance using various metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtyMNTru1CPv"
      },
      "source": [
        "# Single-Layer KAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiI8X88NbAl8",
        "outputId": "9937622c-56d1-4224-a42c-99573ff8d11e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train loss: 4.67e-02 | test loss: 4.79e-01 | reg: 0.00e+00 : 100%|█| 20/20 [42:25<00:00, 127.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9582740788623141\n",
            "Test F1 Score: 0.9582332778022409\n",
            "Test Precision: 0.9594176520477313\n",
            "Test Recall: 0.9582740788623141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/depression_dataset_reddit_cleaned.csv')\n",
        "\n",
        "# Text preprocessing using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df['clean_text']).toarray()\n",
        "y = df['is_depression'].values\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "dataset = {\n",
        "    'train_input': torch.from_numpy(X_train).float(),\n",
        "    'test_input': torch.from_numpy(X_test).float(),\n",
        "    'train_label': torch.from_numpy(y_train).long(),\n",
        "    'test_label': torch.from_numpy(y_test).long()\n",
        "}\n",
        "\n",
        "# Model parameters\n",
        "input_layer_dim = X_train.shape[1]  # Number of features after TF-IDF\n",
        "first_hidden_layer_dim = 100\n",
        "num_class = 2  # Binary classification (0 or 1)\n",
        "\n",
        "# Initialize the KAN model\n",
        "model = KAN(width=[input_layer_dim, first_hidden_layer_dim, num_class], grid=10, k=2)\n",
        "model = model.speed()\n",
        "\n",
        "# Metrics storage\n",
        "acc_train, f1_train, prec_train, recall_train = [], [], [], []\n",
        "acc_test, f1_test, prec_test, recall_test = [], [], [], []\n",
        "\n",
        "def train_acc():\n",
        "    y_pred_true = torch.argmax(model(dataset['train_input']), dim=1)\n",
        "    y_true = dataset['train_label']\n",
        "    acc_train.append(accuracy_score(y_true, y_pred_true))\n",
        "    f1_train.append(f1_score(y_true, y_pred_true, average='weighted'))\n",
        "    prec_train.append(precision_score(y_true, y_pred_true, average='weighted'))\n",
        "    recall_train.append(recall_score(y_true, y_pred_true, average='weighted'))\n",
        "    return np.mean(acc_train)\n",
        "\n",
        "def test_acc():\n",
        "    y_pred_test = torch.argmax(model(dataset['test_input']), dim=1)\n",
        "    y_test = dataset['test_label']\n",
        "    acc_test.append(accuracy_score(y_test, y_pred_test))\n",
        "    f1_test.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
        "    prec_test.append(precision_score(y_test, y_pred_test, average='weighted'))\n",
        "    recall_test.append(recall_score(y_test, y_pred_test, average='weighted'))\n",
        "    return np.mean(acc_test)\n",
        "\n",
        "# Model training\n",
        "results = model.fit(dataset, opt=\"LBFGS\", steps=20, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss())\n",
        "\n",
        "# Display results obtained on test data\n",
        "print(f\"Test Accuracy: {np.mean(acc_test)}\")\n",
        "print(f\"Test F1 Score: {np.mean(f1_test)}\")\n",
        "print(f\"Test Precision: {np.mean(prec_test)}\")\n",
        "print(f\"Test Recall: {np.mean(recall_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eosq7Ydl1KNn"
      },
      "source": [
        "# Two-Layer KAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-poQK0o1Nim",
        "outputId": "64d259e8-1e00-4793-e20f-703707901678"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train loss: 4.82e-02 | test loss: 6.99e-01 | reg: 0.00e+00 : 100%|█| 30/30 [1:01:52<00:00, 123.76s/i"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9539754363283776\n",
            "Test F1 Score: 0.9539222937909848\n",
            "Test Precision: 0.9546275821175949\n",
            "Test Recall: 0.9539754363283776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from kan import KAN\n",
        "from kan import *\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/depression_dataset_reddit_cleaned.csv')\n",
        "\n",
        "# Text preprocessing using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df['clean_text']).toarray()\n",
        "y = df['is_depression'].values\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "dataset = {\n",
        "    'train_input': torch.from_numpy(X_train).float(),\n",
        "    'test_input': torch.from_numpy(X_test).float(),\n",
        "    'train_label': torch.from_numpy(y_train).long(),\n",
        "    'test_label': torch.from_numpy(y_test).long()\n",
        "}\n",
        "\n",
        "# Model parameters\n",
        "input_layer_dim = X_train.shape[1]  # Number of features after TF-IDF\n",
        "first_hidden_layer_dim = 100\n",
        "second_hidden_layer_dim = 75\n",
        "num_class = 2  # Binary classification (0 or 1)\n",
        "\n",
        "# Initialize the KAN model\n",
        "model = KAN(width=[input_layer_dim,first_hidden_layer_dim,second_hidden_layer_dim,num_class], grid=4, k=2)\n",
        "model = model.speed()\n",
        "# Metrics storage\n",
        "acc_train, f1_train, prec_train, recall_train = [], [], [], []\n",
        "acc_test, f1_test, prec_test, recall_test = [], [], [], []\n",
        "\n",
        "def train_acc():\n",
        "    y_pred_true = torch.argmax(model(dataset['train_input']), dim=1)\n",
        "    y_true = dataset['train_label']\n",
        "    acc_train.append(accuracy_score(y_true, y_pred_true))\n",
        "    f1_train.append(f1_score(y_true, y_pred_true, average='weighted'))\n",
        "    prec_train.append(precision_score(y_true, y_pred_true, average='weighted'))\n",
        "    recall_train.append(recall_score(y_true, y_pred_true, average='weighted'))\n",
        "    return np.mean(acc_train)\n",
        "\n",
        "def test_acc():\n",
        "    y_pred_test = torch.argmax(model(dataset['test_input']), dim=1)\n",
        "    y_test = dataset['test_label']\n",
        "    acc_test.append(accuracy_score(y_test, y_pred_test))\n",
        "    f1_test.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
        "    prec_test.append(precision_score(y_test, y_pred_test, average='weighted'))\n",
        "    recall_test.append(recall_score(y_test, y_pred_test, average='weighted'))\n",
        "    return np.mean(acc_test)\n",
        "\n",
        "# Model training\n",
        "results = model.fit(dataset, opt=\"LBFGS\", steps=30, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss())\n",
        "\n",
        "# Display results obtained on test data\n",
        "print(f\"Test Accuracy: {np.mean(acc_test)}\")\n",
        "print(f\"Test F1 Score: {np.mean(f1_test)}\")\n",
        "print(f\"Test Precision: {np.mean(prec_test)}\")\n",
        "print(f\"Test Recall: {np.mean(recall_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DhnpcxZ11uE"
      },
      "source": [
        "# Three-Layer KAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1vHaFPB14N1",
        "outputId": "ac324f0e-d307-4d72-d249-f2bcf21cafce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train loss: 4.51e-02 | test loss: 6.94e-01 | reg: 0.00e+00 : 100%|█| 30/30 [1:07:15<00:00, 134.52s/i"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9473389355742298\n",
            "Test F1 Score: 0.9473090190838374\n",
            "Test Precision: 0.9478148609809689\n",
            "Test Recall: 0.9473389355742298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from kan import KAN\n",
        "from kan import *\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/depression_dataset_reddit_cleaned.csv')\n",
        "\n",
        "# Text preprocessing using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df['clean_text']).toarray()\n",
        "y = df['is_depression'].values\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "dataset = {\n",
        "    'train_input': torch.from_numpy(X_train).float(),\n",
        "    'test_input': torch.from_numpy(X_test).float(),\n",
        "    'train_label': torch.from_numpy(y_train).long(),\n",
        "    'test_label': torch.from_numpy(y_test).long()\n",
        "}\n",
        "\n",
        "# Model parameters\n",
        "input_layer_dim = X_train.shape[1]  # Number of features after TF-IDF\n",
        "first_hidden_layer_dim = 100\n",
        "second_hidden_layer_dim = 75\n",
        "third_hidden_layer_dim = 50\n",
        "num_class = 2  # Binary classification (0 or 1)\n",
        "\n",
        "# Initialize the KAN model\n",
        "model = KAN(width=[input_layer_dim,first_hidden_layer_dim,second_hidden_layer_dim,third_hidden_layer_dim, num_class], grid=4, k=2)\n",
        "model = model.speed()\n",
        "# Metrics storage\n",
        "acc_train, f1_train, prec_train, recall_train = [], [], [], []\n",
        "acc_test, f1_test, prec_test, recall_test = [], [], [], []\n",
        "\n",
        "def train_acc():\n",
        "    y_pred_true = torch.argmax(model(dataset['train_input']), dim=1)\n",
        "    y_true = dataset['train_label']\n",
        "    acc_train.append(accuracy_score(y_true, y_pred_true))\n",
        "    f1_train.append(f1_score(y_true, y_pred_true, average='weighted'))\n",
        "    prec_train.append(precision_score(y_true, y_pred_true, average='weighted'))\n",
        "    recall_train.append(recall_score(y_true, y_pred_true, average='weighted'))\n",
        "    return np.mean(acc_train)\n",
        "\n",
        "def test_acc():\n",
        "    y_pred_test = torch.argmax(model(dataset['test_input']), dim=1)\n",
        "    y_test = dataset['test_label']\n",
        "    acc_test.append(accuracy_score(y_test, y_pred_test))\n",
        "    f1_test.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
        "    prec_test.append(precision_score(y_test, y_pred_test, average='weighted'))\n",
        "    recall_test.append(recall_score(y_test, y_pred_test, average='weighted'))\n",
        "    return np.mean(acc_test)\n",
        "\n",
        "# Model training\n",
        "results = model.fit(dataset, opt=\"LBFGS\", steps=30, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss())\n",
        "\n",
        "# Display results obtained on test data\n",
        "print(f\"Test Accuracy: {np.mean(acc_test)}\")\n",
        "print(f\"Test F1 Score: {np.mean(f1_test)}\")\n",
        "print(f\"Test Precision: {np.mean(prec_test)}\")\n",
        "print(f\"Test Recall: {np.mean(recall_test)}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
